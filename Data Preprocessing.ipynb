{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "from profanity import profanity\n",
    "import csv\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "RAW_DATA_PATH = 'data/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def find_longest_word(word_list):\n",
    "    longest_word =  max(word_list, key=len)\n",
    "    return len(longest_word)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID INTERPRET    TITEL SPRACHE_DEUTSCH  \\\n",
      "0  1148163     Yasha  Strand               Ja   \n",
      "1  1148163     Yasha  Strand               Ja   \n",
      "2  1148163     Yasha  Strand               Ja   \n",
      "3  1148163     Yasha  Strand               Ja   \n",
      "4  1148163     Yasha  Strand               Ja   \n",
      "\n",
      "                                          TEXT_TEIL1 TEXT_TEIL2 TEXT_TEIL3  \\\n",
      "0  LASS UNS ZUM STRAND DU WEISST WELCHEN ICH MEIN...        NaN        NaN   \n",
      "1  LASS UNS ZUM STRAND DU WEISST WELCHEN ICH MEIN...        NaN        NaN   \n",
      "2  LASS UNS ZUM STRAND DU WEISST WELCHEN ICH MEIN...        NaN        NaN   \n",
      "3  LASS UNS ZUM STRAND DU WEISST WELCHEN ICH MEIN...        NaN        NaN   \n",
      "4  LASS UNS ZUM STRAND DU WEISST WELCHEN ICH MEIN...        NaN        NaN   \n",
      "\n",
      "  TEXT_TEIL4  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "   LIED_ID  POSITION   DATUM_VON   DATUM_BIS\n",
      "0    26024        26  1983-04-18  1983-04-24\n",
      "1     1073        46  1984-06-04  1984-06-10\n",
      "2     1131        33  1984-06-18  1984-06-24\n",
      "3    15819        22  1984-08-13  1984-08-19\n",
      "4     7324         6  1984-08-27  1984-09-02\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "df_Lied = pd.read_csv(RAW_DATA_PATH + 'LIED.csv', usecols=['ID','INTERPRET', 'TITEL', 'SPRACHE_DEUTSCH', 'TEXT_TEIL1', 'TEXT_TEIL2', 'TEXT_TEIL3', 'TEXT_TEIL4'])\n",
    "print(df_Lied.head())\n",
    "\n",
    "df_Chart_Position = pd.read_csv(RAW_DATA_PATH + 'CHART_POSITION.csv', usecols=['LIED_ID', 'POSITION', 'DATUM_VON', 'DATUM_BIS'])\n",
    "print(df_Chart_Position.head())\n",
    "\n",
    "with open(RAW_DATA_PATH+'Stoppwords.csv', newline='', encoding='UTF-8') as f:\n",
    "    stopwords_list = list(csv.reader(f))\n",
    "stopwords_list = [word.upper() for word in flatten(stopwords_list)]\n",
    "print(type(stopwords_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Lied['Text'] = df_Lied['TEXT_TEIL1'].fillna('') + df_Lied['TEXT_TEIL2'].fillna('') + df_Lied['TEXT_TEIL3'].fillna('') + df_Lied['TEXT_TEIL4'].fillna('')\n",
    "#df_Lied.drop(columns=['TEXT_TEIL1', 'TEXT_TEIL2', 'TEXT_TEIL3', 'TEXT_TEIL4'], axis=1, inplace=True)\n",
    "\n",
    "df_Chart_Position['DATUM_VON'] = pd.to_datetime(df_Chart_Position['DATUM_VON'])\n",
    "df_Chart_Position['DATUM_BIS'] = pd.to_datetime(df_Chart_Position['DATUM_BIS'])\n",
    "df_Chart_Position['DAUER'] = (df_Chart_Position['DATUM_BIS'] - df_Chart_Position['DATUM_VON']).dt.days.astype('int16')\n",
    "df_Chart_Position['Jahr'] = df_Chart_Position['DATUM_BIS'].dt.year.astype('int16')\n",
    "df_Chart_Position['Monat'] =  df_Chart_Position['DATUM_BIS'].dt.month.astype('int16')\n",
    "\n",
    "#df_Lied['TEXT_LAENGE'] = list(len(word) for word in df_Lied['Text'])\n",
    "df_Lied['ANZ_UNIQUE_WOERTER'] = list(len(set(word.split(\" \"))) for word in df_Lied['Text'])\n",
    "df_Lied['LAENGE_LAENGSTES_WORT'] = list(len(max(set(word.split(\" \")), key=len)) for word in df_Lied['Text'])\n",
    "df_Lied[['LAENGE_LAENGSTES_WORT','ID']].to_csv('Data/processed/Wort_LAENGE_v2.csv')\n",
    "df_Lied['INTERPRET'].value_counts(ascending=True, dropna=True, normalize=True)\\\n",
    "    #.to_csv('Data/processed/Interpret_Occurrences_normalised.csv')\n",
    "\n",
    "MAX_RANK = 50\n",
    "df_Chart_Position['RANK_SCORE'] = MAX_RANK - df_Chart_Position['POSITION'] + 1\n",
    "\n",
    "#df_copy_Chart_Position = df_Chart_Position[\"LIED_ID\"]\n",
    "\n",
    "#df_Chart_Position_Duplicates = df_Chart_Position[df_copy_Chart_Position.isin(df_copy_Chart_Position[df_copy_Chart_Position.duplicated()])].sort_values(\"LIED_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EY  SHAWTY WILL ALLEINE  SEIN  ALLEIN  DENN SIE HAT GERADE BAD VIBES SHAWTY WILL ALLEINE  SEIN  ALLEIN  IST NICHT ERREICHBAR AUF FACETIME  YEAH  MIR GENUEGT SCHON EIN CALL VON DIR  BABY  VON DIR  BABY  KEINER WEISS  WIESO  DOCH DU MACHST MICH SO CRAZY  KEINER WEISS  WIESO  EY  SHAWTY WILL ALLEINE  SEIN  ALLEIN  DENN SIE HAT GERADE BAD VIBES SIE HAT BAD VIBES  BAD VIBES   ES IST LATE NIGHT  NIGHT  ERFUELL IHR JEDEN WUNSCH  DENN WIR LEBEN DAS FAST LIFE  OH  JA  ICH WEISS  ALLE MACHEN AUGE AUF MEIN BABY  BABY  GIB MIR DEIN WORT UND ICH MACH DICH ZU MEINER LADY  JA  VERMISS DICH SCHON  JA  SOBALD ICH AUS DEM HAUS LAUF  OH OH OH  DU FICKST MEIN  N KOPF IRGENDWIE  ABER ICH STEH DRAUF  ICH STEH DRAUF  DU GEHST MIR AUS DEM WEG UND SUCHST DANN WIEDER NAEHE  OH YEAH  WAS DU DIR DABEI DENKST  DAS MUSS MAN NICHT VERSTEHEN MIT DIR FUEHL ICH MICH  ALS WAER ICH IM FINALE  FINALE  SCHEISS AUF ALLES  BRAUCH NUR DICH  KEINE POKALE  POKALE  DU REDEST HIN UND HER UND SENDEST MIR SIGNALE  OHH  DASS DU MICH ZAPPELN LAESST  DAS WISSEN WIR DOCH ALLE SHAWTY WILL ALLEINE  SEIN  ALLEIN  DENN SIE HAT GERADE BAD VIBES SHAWTY WILL ALLEINE  SEIN IST NICHT ERREICHBAR AUF FACETIME MIR GENUEGT SCHON EIN CALL VON DIR  BABY  VON DIR  BABY  KEINER WEISS  WIESO  DOCH DU MACHST MICH SO CRAZY  KEINER WEISS  WIESO  EY  SHAWTY WILL ALLEINE  SEIN  ALLEIN  DENN SIE HAT GERADE BAD VIBES SHAWTY WILL ALLEINE  SEIN  ALLEIN SEIN  WEIL ICH WEISS  DASS SIE SICH GRAD IN   SCHLAF WEINT  JA  JA  JA  OKAY  AUGEN WIE EIN BERNSTEIN  OH WOAH  TREFFEN UNS BEI NACHT  HOEREN  MURDER ON MY MIND  DU UND ICH  WIR CONNECTEN WIE DAS WLAN  WLAN  ZWISCHENDURCH HAT MAL JEDER SEINE FEHLER  JEDER SEINE FEHLER  DU GEHST MIR AUS DEM WEG UND SUCHST DANN WIEDER NAEHE WAS DU DIR DABEI DENKST  DAS MUSS MAN NICHT VERSTEHEN MIT DIR FUEHL ICH MICH  ALS WAER ICH IM FINALE  FINALE  SCHEISS AUF ALLES  BRAUCH NUR DICH  KEINE POKALE  KEINE POKALE  DU REDEST HIN UND HER UND SENDEST MIR SIGNALE  SIGNALE  DASS DU MICH ZAPPELN LAESST  DAS WISSEN WIR DOCH ALLE SHAWTY WILL ALLEINE  SEIN  SHAWTY WILL ALLEINE  SEIN  DENN SIE HAT GERADE BAD VIBES  BAD VIBES  SHAWTY WILL ALLEINE  SEIN  ALLEIN SEIN  IST NICHT ERREICHBAR AUF FACETIME EY  SHAWTY WILL ALLEINE  SEIN  ALLEIN  DENN SIE HAT GERADE BAD VIBES SHAWTY WILL ALLEINE  SEIN IST NICHT ERREICHBAR AUF FACETIME MIR GENUEGT SCHON EIN CALL VON DIR  BABY  VON DIR  BABY  KEINER WEISS  WIESO  DOCH DU MACHST MICH SO CRAZY  KEINER WEISS  WIESO  EY  SHAWTY WILL ALLEINE  SEIN  ALLEIN  DENN SIE HAT GERADE BAD VIBES\n"
     ]
    }
   ],
   "source": [
    "print(df_Lied['Text'][1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'list'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [12], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m df_Lied[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprocessed_text\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_Lied[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprocessed_text\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: [item \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m x \u001B[38;5;28;01mif\u001B[39;00m item \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stopwords_list])\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m#remove numbers\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m \u001B[43mdf_Lied\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprocessed_text\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mw*\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43md\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mw*\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_Lied\u001B[38;5;241m.\u001B[39mhead())\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m#Stemming\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m \n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# ngram\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.2\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4668\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4670\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.2\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1105\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1104\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.2\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1156\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1154\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1155\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1156\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1163\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1164\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.2\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn [12], line 12\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      9\u001B[0m df_Lied[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprocessed_text\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_Lied[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprocessed_text\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: [item \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m x \u001B[38;5;28;01mif\u001B[39;00m item \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stopwords_list])\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m#remove numbers\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m df_Lied[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprocessed_text\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x : \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mw*\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43md\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mw*\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_Lied\u001B[38;5;241m.\u001B[39mhead())\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m#Stemming\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m \n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# ngram\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\__init__.py:185\u001B[0m, in \u001B[0;36msub\u001B[1;34m(pattern, repl, string, count, flags)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msub\u001B[39m(pattern, repl, string, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001B[39;00m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001B[39;00m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001B[39;00m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001B[39;00m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;124;03m    a callable, it's passed the Match object and must return\u001B[39;00m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;124;03m    a replacement string to be used.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: expected string or bytes-like object, got 'list'"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "\n",
    "#df_Lied['Text'].apply(lambda x: \" \".join([word.lemma_ for text in df_Lied['Text'] for word in nlp(text)]))\n",
    "\n",
    "# tokenize\n",
    "df_Lied['processed_text'] = df_Lied.apply(lambda row: nltk.word_tokenize(row['Text']), axis=1)\n",
    "\n",
    "#remove stopwords\n",
    "df_Lied['processed_text'] = df_Lied['processed_text'].apply(lambda x: [item for item in x if item not in stopwords_list])\n",
    "\n",
    "#remove numbers\n",
    "df_Lied['processed_text'].apply(lambda x : re.sub('\\w*\\d\\w*','', x))\n",
    "#print(df_Lied.head())\n",
    "\n",
    "#Stemming\n",
    "\n",
    "\n",
    "# ngram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EY', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'GERADE', 'BAD', 'VIBES', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'ERREICHBAR', 'FACETIME', 'YEAH', 'GENUEGT', 'SCHON', 'CALL', 'BABY', 'BABY', 'WEISS', 'DOCH', 'MACHST', 'CRAZY', 'WEISS', 'EY', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'GERADE', 'BAD', 'VIBES', 'BAD', 'VIBES', 'BAD', 'VIBES', 'LATE', 'NIGHT', 'NIGHT', 'ERFUELL', 'WUNSCH', 'LEBEN', 'FAST', 'LIFE', 'OH', 'JA', 'WEISS', 'MACHEN', 'AUGE', 'BABY', 'BABY', 'GIB', 'MACH', 'LADY', 'JA', 'VERMISS', 'SCHON', 'JA', 'HAUS', 'LAUF', 'OH', 'OH', 'OH', 'FICKST', 'KOPF', 'IRGENDWIE', 'STEH', 'DRAUF', 'STEH', 'DRAUF', 'GEHST', 'WEG', 'SUCHST', 'WIEDER', 'NAEHE', 'OH', 'YEAH', 'DABEI', 'DENKST', 'MUSS', 'VERSTEHEN', 'FUEHL', 'WAER', 'FINALE', 'FINALE', 'SCHEISS', 'BRAUCH', 'NUR', 'POKALE', 'POKALE', 'REDEST', 'HIN', 'HER', 'SENDEST', 'SIGNALE', 'OHH', 'ZAPPELN', 'LAESST', 'WISSEN', 'DOCH', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'GERADE', 'BAD', 'VIBES', 'SHAWTY', 'WILL', 'ALLEINE', 'ERREICHBAR', 'FACETIME', 'GENUEGT', 'SCHON', 'CALL', 'BABY', 'BABY', 'WEISS', 'DOCH', 'MACHST', 'CRAZY', 'WEISS', 'EY', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'GERADE', 'BAD', 'VIBES', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'WEISS', 'GRAD', 'SCHLAF', 'WEINT', 'JA', 'JA', 'JA', 'OKAY', 'AUGEN', 'BERNSTEIN', 'OH', 'WOAH', 'TREFFEN', 'NACHT', 'HOEREN', 'MURDER', 'ON', 'MY', 'MIND', 'CONNECTEN', 'WLAN', 'WLAN', 'ZWISCHENDURCH', 'MAL', 'FEHLER', 'FEHLER', 'GEHST', 'WEG', 'SUCHST', 'WIEDER', 'NAEHE', 'DABEI', 'DENKST', 'MUSS', 'VERSTEHEN', 'FUEHL', 'WAER', 'FINALE', 'FINALE', 'SCHEISS', 'BRAUCH', 'NUR', 'POKALE', 'POKALE', 'REDEST', 'HIN', 'HER', 'SENDEST', 'SIGNALE', 'SIGNALE', 'ZAPPELN', 'LAESST', 'WISSEN', 'DOCH', 'SHAWTY', 'WILL', 'ALLEINE', 'SHAWTY', 'WILL', 'ALLEINE', 'GERADE', 'BAD', 'VIBES', 'BAD', 'VIBES', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'ERREICHBAR', 'FACETIME', 'EY', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'GERADE', 'BAD', 'VIBES', 'SHAWTY', 'WILL', 'ALLEINE', 'ERREICHBAR', 'FACETIME', 'GENUEGT', 'SCHON', 'CALL', 'BABY', 'BABY', 'WEISS', 'DOCH', 'MACHST', 'CRAZY', 'WEISS', 'EY', 'SHAWTY', 'WILL', 'ALLEINE', 'ALLEIN', 'GERADE', 'BAD', 'VIBES']\n"
     ]
    }
   ],
   "source": [
    "print(df_Lied['tokenized_text'][1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "profanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(RAW_DATA_PATH+'german-profanity-list.csv', newline='', encoding='UTF-8') as f:\n",
    "    profanity_list = list(csv.reader(f))\n",
    "\n",
    "profanity.load_words(flatten(profanity_list))\n",
    "profanity.contains_profanity(df_Lied['Text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Percentage of Stopwords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_Lied['Number_of_Stopwords'] = df_Lied['Text'].str.split().apply(lambda x: len(set(x) & set(stopwords_list)))\n",
    "df_Lied['Stopword_Percentage'] = df_Lied.Number_of_Stopwords.apply(lambda row: row/len(df_Lied['Text']))\n",
    "df_Lied[['ID','Number_of_Stopwords','Stopword_Percentage']].to_csv('Data/processed/Stoppwords.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   LIED_ID  POSITION  DATUM_VON  DATUM_BIS  DAUER  Jahr  Monat  RANK_SCORE\n0    26024        26 1983-04-18 1983-04-24      6  1983      4          25\n1     1073        46 1984-06-04 1984-06-10      6  1984      6           5\n2     1131        33 1984-06-18 1984-06-24      6  1984      6          18\n3    15819        22 1984-08-13 1984-08-19      6  1984      8          29\n4     7324         6 1984-08-27 1984-09-02      6  1984      9          45",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIED_ID</th>\n      <th>POSITION</th>\n      <th>DATUM_VON</th>\n      <th>DATUM_BIS</th>\n      <th>DAUER</th>\n      <th>Jahr</th>\n      <th>Monat</th>\n      <th>RANK_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26024</td>\n      <td>26</td>\n      <td>1983-04-18</td>\n      <td>1983-04-24</td>\n      <td>6</td>\n      <td>1983</td>\n      <td>4</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1073</td>\n      <td>46</td>\n      <td>1984-06-04</td>\n      <td>1984-06-10</td>\n      <td>6</td>\n      <td>1984</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1131</td>\n      <td>33</td>\n      <td>1984-06-18</td>\n      <td>1984-06-24</td>\n      <td>6</td>\n      <td>1984</td>\n      <td>6</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15819</td>\n      <td>22</td>\n      <td>1984-08-13</td>\n      <td>1984-08-19</td>\n      <td>6</td>\n      <td>1984</td>\n      <td>8</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7324</td>\n      <td>6</td>\n      <td>1984-08-27</td>\n      <td>1984-09-02</td>\n      <td>6</td>\n      <td>1984</td>\n      <td>9</td>\n      <td>45</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Chart_Position.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA (BoW) - Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "titel_list = [word.upper() for word in list(set(df_Lied['TITEL']))]\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized_list = [word for titel in titel_list for word in tokenizer.tokenize(titel)]\n",
    "no_stopwords_title_list = [item for item in tokenized_list if item not in stopwords_list]\n",
    "df_title_word_occurrence = pd.value_counts(np.array(no_stopwords_title_list))\n",
    "df_title_word_occurrence.to_csv('Data/processed/title_word_occurrence.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosted Words -Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.merge(df_Lied, df_Chart_Position.set_axis(['DATUM_VON','DATUM_BIS', 'ID', 'POSITION', 'DAUER', 'BELIEBTHEIT', 'Jahr', 'Monat'], axis=1, inplace=False), on='ID', how='inner').sort_values(by=['ID'])\n",
    "print(df_Lied.isnull().values.any())#df muss noch ausgetauscht werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
